{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Questions to be answered\n",
        "# Question 1: Neighbourhood with most Airbnb houses with WIFI and laptop friendly workplaces\n",
        "# Question 2: Neighbourhood with most Airbnb houses with cleansed neighborhoods\n",
        "# Question 3: Neighbourhood with the largest number of highest review scores\n",
        "# Question 4: Most important features that affect the prices"
      ],
      "metadata": {
        "id": "lOGnd4bVDygL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFIrFdlnDmx7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'listings.csv'\n",
        "listings_data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "iTteUm_FDtEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check if both WIFI and laptop friendly workplaces are present in the amenities\n",
        "def has_required_amenities(amenities):\n",
        "    required_amenities = {\"Wireless Internet\", \"Laptop Friendly Workspace\"}\n",
        "    amenities_set = set(amenity.strip('\"') for amenity in amenities.strip('{}').split(','))\n",
        "    return required_amenities.issubset(amenities_set)"
      ],
      "metadata": {
        "id": "GnHN-lMgDtGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to filter listings with required amenities\n",
        "filtered_df = listings_data[listings_data['amenities'].apply(has_required_amenities)]"
      ],
      "metadata": {
        "id": "8AP16ZnFDtJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1: Neighbourhood with most Airbnb houses with WIFI and laptop friendly workplaces\n",
        "neighbourhood_with_most_wifi_and_laptop_friendly = filtered_df['neighbourhood_cleansed'].value_counts().idxmax()\n"
      ],
      "metadata": {
        "id": "Aipt1MxJDtLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 2: Neighbourhood with most Airbnb houses with cleansed neighborhoods\n",
        "neighbourhood_with_most_cleansed = listings_data['neighbourhood_cleansed'].value_counts().idxmax()"
      ],
      "metadata": {
        "id": "9qp7961jDtQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3: Neighbourhood with the largest number of highest review scores\n",
        "listings_data['review_scores_rating'] = listings_data['review_scores_rating'].fillna(0)\n",
        "neighbourhood_with_highest_reviews = listings_data.groupby('neighbourhood_cleansed')['review_scores_rating'].max().idxmax()\n"
      ],
      "metadata": {
        "id": "xEO7Fqe6DtTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Analysis for Price\n",
        "# Selectt relevant features for the analysis\n",
        "features = ['neighbourhood_cleansed', 'room_type', 'accommodates', 'bathrooms', 'bedrooms',\n",
        "            'beds', 'amenities', 'number_of_reviews', 'review_scores_rating', 'instant_bookable']\n",
        "target = 'price'"
      ],
      "metadata": {
        "id": "37X82UddDtV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert price to a numeric value\n",
        "listings_data['price'] = listings_data['price'].replace('[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "# Handling missing values\n",
        "listings_data[features] = listings_data[features].fillna(listings_data[features].mean(numeric_only=True))\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(listings_data[features], listings_data[target], test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating a preprocessing pipeline\n",
        "numeric_features = listings_data[features].select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = listings_data[features].select_dtypes(include=['object']).columns"
      ],
      "metadata": {
        "id": "9uuhQkTeDtYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])"
      ],
      "metadata": {
        "id": "2j0Rkfm_DtbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the regression model\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('regressor', LinearRegression())])\n"
      ],
      "metadata": {
        "id": "zCmvFbgFDtdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "OMoULdlBDtgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predicting and evaluating the model\n",
        "y_pred = model.predict(X_test)\n",
        "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
        "print('Coefficient of Determination:', r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "dytjZK9wDtiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyzing feature importance\n",
        "if hasattr(model.named_steps['regressor'], 'coef_'):\n",
        "    coefficients = model.named_steps['regressor'].coef_\n",
        "    feature_names = numeric_features.tolist() + \\\n",
        "                    list(model.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names(categorical_features))\n",
        "    feature_importance = pd.Series(coefficients, index=feature_names)\n",
        "    print(\"\\nFeature importances:\\n\", feature_importance.sort_values(ascending=False))\n"
      ],
      "metadata": {
        "id": "o8QQffBBDtlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Na3wp6YCDtoW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}